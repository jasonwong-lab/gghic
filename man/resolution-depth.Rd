% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/resolution-depth.R
\name{resolution-depth}
\alias{resolution-depth}
\alias{calculateResolutionDepth}
\alias{calculateGenomeCoverage}
\alias{findOptimalResolution}
\alias{readPairsCache}
\alias{calculateResolutionDepthChunked}
\alias{calculateGenomeCoverageChunked}
\alias{findOptimalResolutionChunked}
\title{Calculate Resolution and Depth for Pairs Data}
\usage{
calculateResolutionDepth(pairs, bin_size)

calculateGenomeCoverage(pairs, bin_size, min_contacts = 1000)

findOptimalResolution(
  pairs,
  min_bin = 1000,
  max_bin = 5e+06,
  target_coverage = 0.8,
  min_contacts = 1000
)

readPairsCache(pairs_file)

calculateResolutionDepthChunked(pairs_file = NULL, bin_size, cache = NULL)

calculateGenomeCoverageChunked(
  pairs_file = NULL,
  bin_size,
  min_contacts = 1000,
  cache = NULL
)

findOptimalResolutionChunked(
  pairs_file = NULL,
  min_bin = 1000,
  max_bin = 5e+06,
  target_coverage = 0.8,
  min_contacts = 1000,
  cache = NULL,
  return_cache = FALSE
)
}
\arguments{
\item{pairs}{A data frame or tibble with columns:
\code{read_name}, \code{chrom1}, \code{pos1}, \code{chrom2}, \code{pos2}.
Can also have additional columns like \code{strand1}, \code{strand2}, etc.
For large files, use \code{pairs_file} parameter instead to read in chunks.}

\item{bin_size}{Integer bin size in base pairs.}

\item{min_contacts}{Integer minimum number of contacts required for a bin.
Default: 1000.}

\item{min_bin}{Integer minimum bin size for search. Default: 1000.}

\item{max_bin}{Integer maximum bin size for search. Default: 5000000.}

\item{target_coverage}{Numeric target coverage fraction (0-1). Default: 0.8.}

\item{pairs_file}{Character path to pairs file.}

\item{cache}{External pointer to cached pairs data (from \code{readPairsCache()}).
If provided, data is read from cache instead of file for much faster
repeated operations.}

\item{return_cache}{Logical, if TRUE, \code{findOptimalResolutionChunked()}
returns a list with both the optimal bin size and the cache pointer.
Default: FALSE.}
}
\value{
\itemize{
\item \code{calculateResolutionDepth()}: A tibble with columns \code{chrom},
\code{bin}, and \code{count}.
\item \code{calculateGenomeCoverage()}: A numeric value representing the fraction
of bins with >= min_contacts.
\item \code{findOptimalResolution()}: An integer representing the optimal bin size.
\item \code{calculateResolutionDepthChunked()}: Same as above, reads file in chunks.
\item \code{calculateGenomeCoverageChunked()}: Coverage calculation from file.
\item \code{findOptimalResolutionChunked()}: Optimal resolution for large files.
}

An external pointer to the cached data.
}
\description{
Functions to analyze genomic interaction data resolution and coverage depth.

Load a pairs file into C memory for fast repeated analysis.
The cache persists until garbage collected or explicitly cleared.
}
\details{
These functions analyze Hi-C pairs data to determine optimal genomic resolution.
\code{calculateResolutionDepth()} bins genomic positions and counts unique
interactions per bin. \code{calculateGenomeCoverage()} computes the fraction of
bins meeting a contact threshold. \code{findOptimalResolution()} uses binary
search to find the smallest bin size achieving target coverage.

For large files that don't fit in memory, use the \verb{_chunked} variants with
\code{pairs_file} parameter. These read the file in chunks and aggregate results.

For large datasets, C-accelerated computation is used when available.
}
\examples{
\dontrun{
# Load pairs data
pairs <- read.table("contact_matrix.txt",
  header = FALSE,
  col.names = c(
    "read_name", "strand1", "chrom1", "pos1", "frag1",
    "strand2", "chrom2", "pos2", "frag2", "mapq1", "mapq2"
  )
)

# Calculate resolution and depth
depth_10kb <- calculateResolutionDepth(pairs, bin_size = 10000)

# For large file, read in chunks
depth_10kb <- calculateResolutionDepthChunked(
  pairs_file = "contact_matrix.txt",
  bin_size = 10000
)

# Calculate coverage
coverage <- calculateGenomeCoverage(pairs, bin_size = 10000)

# Find optimal resolution
opt_bin <- findOptimalResolution(pairs, target_coverage = 0.8)

# For large file - method 1: let function read file each time
opt_bin <- findOptimalResolutionChunked(
  pairs_file = "contact_matrix.txt",
  target_coverage = 0.8
)

# For large file - method 2: cache once, reuse many times (FASTER!)
cache <- readPairsCache("contact_matrix.txt")

# Find optimal resolution using cache
opt_bin <- findOptimalResolutionChunked(cache = cache, target_coverage = 0.8)

# Reuse cache for multiple analyses (no file I/O!)
depth_10kb <- calculateResolutionDepthChunked(cache = cache, bin_size = 10000)
depth_50kb <- calculateResolutionDepthChunked(cache = cache, bin_size = 50000)
coverage <- calculateGenomeCoverageChunked(cache = cache, bin_size = 10000)

# Method 3: Get cache back from findOptimalResolutionChunked
result <- findOptimalResolutionChunked(
  pairs_file = "contact_matrix.txt",
  target_coverage = 0.8,
  return_cache = TRUE
)
opt_bin <- result$bin_size
cache <- result$cache

# Now reuse the cache
depth <- calculateResolutionDepthChunked(cache = cache, bin_size = opt_bin)
}

\dontrun{
# Create cache once
cache <- readPairsCache("data.pairs.gz")

# Reuse cache for multiple operations
depth1 <- calculateResolutionDepthChunked(cache = cache, bin_size = 10000)
depth2 <- calculateResolutionDepthChunked(cache = cache, bin_size = 50000)
coverage <- calculateGenomeCoverageChunked(cache = cache, bin_size = 10000)

# Cache is automatically freed when R session ends
# Or explicitly remove it:
rm(cache)
gc()
}

}
